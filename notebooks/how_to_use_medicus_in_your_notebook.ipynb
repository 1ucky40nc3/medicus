{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1ucky40nc3/medicus/blob/v0.1/notebooks/how_to_use_medicus_in_your_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muihiE4CHihq"
      },
      "outputs": [],
      "source": [
        "!git clone  https://github.com/1ucky40nc3/medicus.git\n",
        "\n",
        "%cd medicus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "!pip install colour"
      ],
      "metadata": {
        "id": "S60kodFwKlsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the data"
      ],
      "metadata": {
        "id": "6nClnqARvEWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "Wjs1cHSQwYBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"shapes\"\n",
        "dataset_dir = f\"/content/datasets/simulated/{dataset_name}\"\n",
        "dataset_file = f\"{dataset_dir}/{dataset_name}.zip\"\n",
        "gdrive_file_id = '1TfmxAfdOL4UouMQMELCzJkTrHr4hclmQ'"
      ],
      "metadata": {
        "id": "8mmpKXF_waTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p $dataset_dir\n",
        "\n",
        "downloaded = drive.CreateFile({'id': gdrive_file_id})\n",
        "downloaded.GetContentFile(dataset_file)\n",
        "\n",
        "!unzip $dataset_file -d $dataset_dir"
      ],
      "metadata": {
        "id": "YGO_WePvLgyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dependencies"
      ],
      "metadata": {
        "id": "BgJoObPKvILn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "\n",
        "from colour import Color\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "import torchvision.transforms as TF\n",
        "\n",
        "from medicus.models import UNet\n",
        "from medicus.objectives.unet import bce_and_softdiceloss\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "4RYqjn1ONQ1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "from typing import Optional\n",
        "from typing import Callable\n",
        "from typing import Any\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "\n",
        "from medicus.data.utils import list_dataset_files\n",
        "from medicus.data.utils import set_seed\n",
        "from medicus.data.datasets import SharedTransformNumpyDataset"
      ],
      "metadata": {
        "id": "VWXdf7nCyM1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the dataset"
      ],
      "metadata": {
        "id": "6ox5U6NTu-1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shared_transform = TF.Compose([\n",
        "    TF.Lambda(lambda x: torch.from_numpy(x)),\n",
        "    TF.Resize((104, 104)),\n",
        "])\n",
        "\n",
        "train_dataset = SharedTransformNumpyDataset(\n",
        "    f\"{dataset_dir}/{dataset_name}/train/samples\",\n",
        "    f\"{dataset_dir}/{dataset_name}/train/targets\",\n",
        "    shared_transform=shared_transform,\n",
        "    return_untransformed_sample=False\n",
        ")\n",
        "test_dataset = SharedTransformNumpyDataset(\n",
        "    f\"{dataset_dir}/{dataset_name}/eval/samples\",\n",
        "    f\"{dataset_dir}/{dataset_name}/eval/targets\",\n",
        "    shared_transform=shared_transform,\n",
        "    return_untransformed_sample=False\n",
        ")"
      ],
      "metadata": {
        "id": "D56ifl7uOKD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "qcGbH78xPNVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "z8np-gUjtn4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the training"
      ],
      "metadata": {
        "id": "yALTplUAVUap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "from typing import Dict\n",
        "from typing import Tuple\n",
        "from typing import Callable\n",
        "from typing import Optional\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import json\n",
        "import logging\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.utils import tensorboard\n",
        "from torchmetrics import MeanMetric\n",
        "\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "Device = Any\n",
        "LRScheduler = Any"
      ],
      "metadata": {
        "id": "Y51IlngaKXm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def timestamp() -> str:\n",
        "    return time.strftime(\n",
        "        \"%Y%m%d%H%M%S\", \n",
        "        time.localtime()\n",
        "    )"
      ],
      "metadata": {
        "id": "zt9A4vbsWJJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(\n",
        "    model: nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    loss_fn: Callable,\n",
        "    device: Device,\n",
        "    log_every: int = 50,\n",
        "    desc: str = \"Evaluating...\",\n",
        "    tqdm_config: dict = {}\n",
        ") -> Any:\n",
        "    model.eval()\n",
        "\n",
        "    metric = MeanMetric()\n",
        "    with torch.no_grad():\n",
        "        with tqdm(dataloader, desc=desc, unit=\"batch\", **tqdm_config) as iterator:\n",
        "            for i, (x, y) in enumerate(iterator):\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                outputs = model(x)\n",
        "                loss = loss_fn(outputs, y)\n",
        "                metric.update(loss.cpu())\n",
        "\n",
        "                if (i + 1) % log_every == 0:\n",
        "                    iterator.set_postfix(\n",
        "                        mean_loss=metric.compute().item())\n",
        "\n",
        "    return metric.compute()"
      ],
      "metadata": {
        "id": "MxG80plV5KFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(\n",
        "    model: nn.Module,\n",
        "    samples: torch.Tensor,\n",
        "    device: Device\n",
        ") -> Tuple[torch.Tensor]:\n",
        "    with torch.no_grad():\n",
        "        samples = samples.to(device)\n",
        "        outputs = model(samples)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "Kb8keD0otPYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse(config) -> dict:\n",
        "    return {\n",
        "        \"model\": {\n",
        "            \"name\": config[\"model\"].__name__,\n",
        "            \"config\": config[\"model_config\"]\n",
        "        },\n",
        "        \"loss_fn\": config[\"loss_fn\"].__name__,\n",
        "        \"optimizer\": {\n",
        "            \"name\": config[\"optimizer\"].__name__,\n",
        "            \"config\": config[\"optimizer_config\"]\n",
        "        },\n",
        "        \"lr_scheduler\": {\n",
        "            \"name\": config[\"lr_scheduler\"].__name__,\n",
        "            \"config\": config[\"lr_scheduler_config\"]\n",
        "        },\n",
        "        \"num_epochs\": config[\"num_epochs\"],\n",
        "        \"log_dir\": config[\"log_dir\"],\n",
        "        \"save_dir\": config[\"save_dir\"],\n",
        "        \"log_every\": config[\"log_every\"],\n",
        "        \"eval_every\": config[\"eval_every\"],\n",
        "        \"save_every\": config[\"save_every\"],\n",
        "        \"methods\": config[\"methods\"],\n",
        "        \"project\": config[\"project\"],\n",
        "        \"notes\": config[\"notes\"],\n",
        "        \"tags\": config[\"tags\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "zc-KTITqVrjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masks2imgs(masks):\n",
        "    masks = masks.cpu().numpy()\n",
        "    batch, channels, height, width = masks.shape\n",
        "\n",
        "    red, blue = Color(\"red\"), Color(\"blue\")\n",
        "    colors = list(red.range_to(blue, channels))\n",
        "    colors = np.array([c.rgb for c in colors]) * 255\n",
        "\n",
        "    imgs = np.ones(\n",
        "        (batch, height, width, 3), \n",
        "        dtype=np.float32\n",
        "    ) * 255\n",
        "\n",
        "    for i in range(batch):\n",
        "        for y in range(height):\n",
        "            for x in range(width):\n",
        "                selected_colors = colors[masks[i, :, y, x] > 0.5]\n",
        "\n",
        "                if len(selected_colors) > 0:\n",
        "                    imgs[i, y, x, :] = np.mean(selected_colors, axis=0)\n",
        "\n",
        "    imgs = imgs.transpose((0, 3, 1, 2))\n",
        "    imgs = torch.from_numpy(imgs).contiguous()\n",
        "    imgs = imgs.float().div(255)\n",
        "\n",
        "    return imgs"
      ],
      "metadata": {
        "id": "HJh-XMJ8Hqu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "\n",
        "!wandb login"
      ],
      "metadata": {
        "id": "jBLMPzEfyXxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "\n",
        "class Logger:\n",
        "    \"\"\"A Logger class.\n",
        "\n",
        "    Log scalars and images with Tensorboard or Weights & Biases.\n",
        "    This makes the use of multiple methods very easy. Simply supply\n",
        "    a list of the types of summary writer to log with.\n",
        "\n",
        "    Attrs:\n",
        "        types (list[str]): The types of summary writers to log to.\n",
        "                           Possible values are ('tensorboard', 'w&b').\n",
        "        log_dir (str): The directory to write log files to.\n",
        "        project (optional, str): The project name to log to. (Needed for 'w&b')\n",
        "        config (optional, str): A runs config. (Needed for 'w&b')\n",
        "    \"\"\"\n",
        "    logger_methods: Tuple[str] = (\"tensorboard\", \"w&b\")\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        methods: Tuple[str],\n",
        "        log_dir: str,\n",
        "        project: Optional[str] = None,\n",
        "        config: Optional[dict] = None,\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        assert all(t in self.logger_methods for t in methods), (\n",
        "            \"Error: A wrong item in `logger_methods` was supplied! \" + \n",
        "            f\"All possible logger types are: {self.logger_methods}\")\n",
        "        \n",
        "        self.methods = set(methods)\n",
        "        self.log_dir = log_dir\n",
        "        self.project = project\n",
        "        self.config = config\n",
        "\n",
        "        for method in self.methods:\n",
        "            attrs = {\n",
        "                **kwargs,\n",
        "                \"log_dir\": log_dir, \n",
        "                \"project\": project, \n",
        "                \"config\": config,\n",
        "            }\n",
        "            self.map(\"init\", method, attrs)\n",
        "\n",
        "    def init_tb(self, log_dir: str, **kwargs) -> None:\n",
        "        self.tb_writer = tensorboard.SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "    def init_wb(self, project: str, config: str, **kwargs) -> None:\n",
        "        assert project is not None, \"Error: Weights & Biases logging shall be used, but no `project` is supplied!\"\n",
        "        assert config is not None, \"Error: Weights & Biases logging shall be used, but no `config` is supplied!\"\n",
        "\n",
        "        wandb.init(project=project, config=config)\n",
        "\n",
        "    def scalar_tb(self, name: str, value: float, step: int) -> None:\n",
        "        self.tb_writer.add_scalar(name, value, step)\n",
        "\n",
        "    def scalar_wb(self, name: str, value: float, step: int) -> None:\n",
        "        wandb.log({name: value}, step=step)\n",
        "\n",
        "    def images_tb(self, name: str, images: torch.Tensor, step: int) -> None:\n",
        "        self.tb_writer.add_images(name, images, step)\n",
        "\n",
        "    def images_wb(self, name: str, images: torch.Tensor, step: int) -> None:\n",
        "        table = wandb.Table(columns=['ID', 'Image'])\n",
        "\n",
        "        for id, img in zip(range(len(images)), images):\n",
        "            img = F.to_pil_image(img)\n",
        "            img = wandb.Image(img)\n",
        "            table.add_data(id, img)\n",
        "\n",
        "        wandb.log({name: table}, step=step)\n",
        "\n",
        "    def map(self, action: str, method: str, attrs: dict) -> None:\n",
        "        mapping = {\n",
        "            \"init\": {\n",
        "                \"tensorboard\": self.init_tb,\n",
        "                \"w&b\": self.init_wb\n",
        "            },\n",
        "            \"scalar\": {\n",
        "                \"tensorboard\": self.scalar_tb,\n",
        "                \"w&b\": self.scalar_wb\n",
        "            },\n",
        "            \"images\": {\n",
        "                \"tensorboard\": self.images_tb,\n",
        "                \"w&b\": self.images_wb\n",
        "            }\n",
        "        }\n",
        "\n",
        "        func = mapping[action][method]\n",
        "        func(**attrs)\n",
        "\n",
        "    def scalar(self, name: str, value: float, step: int) -> None:\n",
        "        for method in self.methods:\n",
        "            attrs = {\n",
        "                \"name\": name, \n",
        "                \"value\": value, \n",
        "                \"step\": step\n",
        "            }\n",
        "            self.map(\"scalar\", method, attrs)\n",
        "\n",
        "    def images(self, name: str, images: torch.Tensor, step: int) -> None:\n",
        "        for method in self.methods:\n",
        "            attrs = {\n",
        "                \"name\": name, \n",
        "                \"images\": images, \n",
        "                \"step\": step\n",
        "            }\n",
        "            self.map(\"images\", method, attrs)"
      ],
      "metadata": {
        "id": "eV-RrpC1u7nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    model: nn.Module,\n",
        "    loss_fn: Callable,\n",
        "    optimizer: optim.Optimizer,\n",
        "    lr_scheduler: LRScheduler,\n",
        "    train_dataloader: DataLoader,\n",
        "    eval_dataloader: DataLoader,\n",
        "    num_epochs: int = 20,\n",
        "    model_config: Dict[str, Any] = {},\n",
        "    optimizer_config: Dict[str, Any] = {},\n",
        "    lr_scheduler_config: Dict[str, Any] = {},\n",
        "    device: Optional[str] = None,\n",
        "    log_dir: str = \"runs/{}/logs\",\n",
        "    save_dir: str = \"runs/{}/checkpoints\",\n",
        "    resume_from: Optional[str] = None,\n",
        "    log_every: int = 50,\n",
        "    eval_every: int = 4_000,\n",
        "    save_every: int = 20_000,\n",
        ") -> None:\n",
        "    run_id = timestamp()\n",
        "    log_dir = log_dir.format(run_id)\n",
        "    save_dir = save_dir.format(run_id)\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Starting new run with id: {run_id}\")\n",
        "    print(f\"Saving logs at:           {log_dir}\")\n",
        "    print(f\"Saving checkpoints at:    {save_dir}\")\n",
        "\n",
        "    config = parse(locals())\n",
        "    print(\"Run with config:\")\n",
        "    print(json.dumps(config, indent=2))\n",
        "    config_path = f\"{log_dir}/config.json\"\n",
        "    print(f\"Saving config at: {config_path}\")\n",
        "    with open(config_path, \"w\") as file:\n",
        "        json.dump(config, file)\n",
        "\n",
        "    writer = tensorboard.SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model(**model_config)\n",
        "    model = model.to(device)\n",
        "\n",
        "    sample, _ = next(iter(train_dataloader))\n",
        "    summary(model, input_size=sample.shape[1:])\n",
        "\n",
        "    optimizer = optimizer(model.parameters(), **optimizer_config)\n",
        "    lr_scheduler = lr_scheduler(optimizer, **lr_scheduler_config)\n",
        "\n",
        "    resume_epoch = 0\n",
        "    resume_step = 0\n",
        "    global_step = 0\n",
        "\n",
        "    test_samples, test_targets = next(iter(eval_dataloader))\n",
        "\n",
        "    if resume_from:\n",
        "        state_dict = torch.load(resume_from)\n",
        "\n",
        "        model.load_state_dict(state_dict[\"model\"])\n",
        "        optimizer.load_state_dict(state_dict[\"optimizer\"])\n",
        "        lr_scheduler.load_state_dict(state_dict[\"lr_scheduler\"])\n",
        "\n",
        "        last_loss = state_dict[\"loss\"]\n",
        "        resume_epoch = state_dict[\"epoch\"]\n",
        "        resume_step = state_dict[\"step\"]\n",
        "        global_step = (resume_step + 1) + resume_epoch * len(train_dataloader)\n",
        "\n",
        "        test_samples = state_dict[\"test_samples\"]\n",
        "        test_targets = state_dict[\"test_targets\"]\n",
        "\n",
        "        print(f\"Resuming training from checkpoint at {resume_from}\")\n",
        "        print(f\"    Last loss:             {last_loss}\")\n",
        "        print(f\"    Resumed epoch:         {resume_epoch}\")\n",
        "        print(f\"    Resumed step in epoch: {resume_step}\")\n",
        "        print(f\"    Resumed global step:   {global_step}\")\n",
        "\n",
        "    writer.add_images(\n",
        "        f\"Images/eval_img_samples\",\n",
        "        img_tensor=test_samples,\n",
        "        global_step=global_step)\n",
        "    \n",
        "    writer.add_images(\n",
        "        f\"Images/eval_img_targets\",\n",
        "        img_tensor=masks2imgs(test_targets),\n",
        "        global_step=global_step)\n",
        "\n",
        "    for i in range(resume_epoch, num_epochs):\n",
        "        desc = f\"Training...[{i + 1}/{num_epochs}]\"\n",
        "        tqdm_config = {\"position\": 0, \"leave\": False}\n",
        "        with tqdm(train_dataloader, desc=desc, unit=\"batch\", **tqdm_config) as iterator:\n",
        "            metric = MeanMetric()\n",
        "\n",
        "            for j, (x, y) in enumerate(iterator):\n",
        "                # Skip forward until the resume step is reached.\n",
        "                # If no checkpoint is provided this isn't invoked.\n",
        "                if resume_step:\n",
        "                    if resume_step == j:\n",
        "                        resume_step = 0\n",
        "                    else:\n",
        "                        continue\n",
        "                global_step = (j + 1) + i * len(iterator)\n",
        "\n",
        "                model.train()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                outputs = model(x)\n",
        "                loss = loss_fn(outputs, y)\n",
        "\n",
        "                if not math.isfinite(loss.item()) or torch.isnan(loss):\n",
        "                    print(f\"Loss is {loss.item()}... stopping training!\")\n",
        "                    return # Just return to stop training ¯\\_(ツ)_/¯\n",
        "                \n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                lr_scheduler.step()\n",
        "                metric.update(loss.cpu().item())\n",
        "\n",
        "                if global_step % log_every == 0:\n",
        "                    mean_loss = metric.compute()\n",
        "                    metric = MeanMetric()\n",
        "\n",
        "                    iterator.set_postfix(\n",
        "                        mean_loss=mean_loss.item())\n",
        "                    writer.add_scalar(\n",
        "                        \"Loss/train_mean_log_step\",\n",
        "                        scalar_value=mean_loss, \n",
        "                        global_step=global_step)\n",
        "                \n",
        "                if global_step % eval_every == 0:\n",
        "                    outputs = inference(\n",
        "                        model, test_samples, device=device)\n",
        "\n",
        "                    writer.add_images(\n",
        "                        f\"Images/eval_img_outputs\",\n",
        "                        img_tensor=masks2imgs(outputs),\n",
        "                        global_step=global_step)\n",
        "\n",
        "                    eval_mean_loss = evaluate(\n",
        "                        model, \n",
        "                        eval_dataloader, \n",
        "                        loss_fn, \n",
        "                        device=device,\n",
        "                        tqdm_config=tqdm_config)\n",
        "                    \n",
        "                    iterator.set_postfix(\n",
        "                        eval_mean_loss=eval_mean_loss.item())\n",
        "                    writer.add_scalar(\n",
        "                        \"Loss/eval_mean\",\n",
        "                        eval_mean_loss,\n",
        "                        global_step=global_step)\n",
        "                    \n",
        "                if global_step % save_every == 0:\n",
        "                    torch.save({\n",
        "                        \"model\": model.state_dict(),\n",
        "                        \"optimizer\": optimizer.state_dict(),\n",
        "                        \"lr_scheduler\": lr_scheduler.state_dict(),\n",
        "                        \"loss\": loss,\n",
        "                        \"epoch\": i,\n",
        "                        \"step\": j,\n",
        "                        \"test_samples\": test_samples,\n",
        "                        \"test_targets\": test_targets\n",
        "                    }, f\"{save_dir}/ckpt_{global_step}\")"
      ],
      "metadata": {
        "id": "_KzpU5XZP_ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "def train(\n",
        "    model: nn.Module,\n",
        "    loss_fn: Callable,\n",
        "    optimizer: optim.Optimizer,\n",
        "    lr_scheduler: LRScheduler,\n",
        "    train_dataloader: DataLoader,\n",
        "    eval_dataloader: DataLoader,\n",
        "    num_epochs: int = 20,\n",
        "    model_config: Dict[str, Any] = {},\n",
        "    optimizer_config: Dict[str, Any] = {},\n",
        "    lr_scheduler_config: Dict[str, Any] = {},\n",
        "    device: Optional[str] = None,\n",
        "    log_dir: str = \"runs/{}/logs\",\n",
        "    save_dir: str = \"runs/{}/checkpoints\",\n",
        "    resume_from: Optional[str] = None,\n",
        "    log_every: int = 50,\n",
        "    eval_every: int = 4_000,\n",
        "    save_every: int = 20_000,\n",
        "    methods: Tuple[str] = (\"tensorboard\",),\n",
        "    project: Optional[str] = None,\n",
        "    notes: Optional[str] = None,\n",
        "    tags: Optional[List[str]] = None\n",
        ") -> None:\n",
        "    run_id = timestamp()\n",
        "    log_dir = log_dir.format(run_id)\n",
        "    save_dir = save_dir.format(run_id)\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Starting new run with id: {run_id}\")\n",
        "    print(f\"Saving logs at:           {log_dir}\")\n",
        "    print(f\"Saving checkpoints at:    {save_dir}\")\n",
        "\n",
        "    config = parse(locals())\n",
        "    print(\"Run with config:\")\n",
        "    print(json.dumps(config, indent=2))\n",
        "    config_path = f\"{log_dir}/config.json\"\n",
        "    print(f\"Saving config at: {config_path}\")\n",
        "    with open(config_path, \"w\") as file:\n",
        "        json.dump(config, file)\n",
        "\n",
        "    writer = Logger(**config)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model(**model_config)\n",
        "    model = model.to(device)\n",
        "\n",
        "    sample, _ = next(iter(train_dataloader))\n",
        "    summary(model, input_size=sample.shape[1:])\n",
        "\n",
        "    optimizer = optimizer(model.parameters(), **optimizer_config)\n",
        "    lr_scheduler = lr_scheduler(optimizer, **lr_scheduler_config)\n",
        "\n",
        "    resume_epoch = 0\n",
        "    resume_step = 0\n",
        "    global_step = 0\n",
        "\n",
        "    test_samples, test_targets = next(iter(eval_dataloader))\n",
        "\n",
        "    if resume_from:\n",
        "        state_dict = torch.load(resume_from)\n",
        "\n",
        "        model.load_state_dict(state_dict[\"model\"])\n",
        "        optimizer.load_state_dict(state_dict[\"optimizer\"])\n",
        "        lr_scheduler.load_state_dict(state_dict[\"lr_scheduler\"])\n",
        "\n",
        "        last_loss = state_dict[\"loss\"]\n",
        "        resume_epoch = state_dict[\"epoch\"]\n",
        "        resume_step = state_dict[\"step\"]\n",
        "        global_step = (resume_step + 1) + resume_epoch * len(train_dataloader)\n",
        "\n",
        "        test_samples = state_dict[\"test_samples\"]\n",
        "        test_targets = state_dict[\"test_targets\"]\n",
        "\n",
        "        print(f\"Resuming training from checkpoint at {resume_from}\")\n",
        "        print(f\"    Last loss:             {last_loss}\")\n",
        "        print(f\"    Resumed epoch:         {resume_epoch}\")\n",
        "        print(f\"    Resumed step in epoch: {resume_step}\")\n",
        "        print(f\"    Resumed global step:   {global_step}\")\n",
        "\n",
        "    writer.images(\"Images/test_samples\", test_samples, global_step)\n",
        "    writer.images(\"Images/test_targets\", masks2imgs(test_targets), global_step)\n",
        "\n",
        "    for i in range(resume_epoch, num_epochs):\n",
        "        desc = f\"Training...[{i + 1}/{num_epochs}]\"\n",
        "        tqdm_config = {\"position\": 0, \"leave\": False}\n",
        "        with tqdm(train_dataloader, desc=desc, unit=\"batch\", **tqdm_config) as iterator:\n",
        "            metric = MeanMetric()\n",
        "\n",
        "            for j, (x, y) in enumerate(iterator):\n",
        "                # Skip forward until the resume step is reached.\n",
        "                # If no checkpoint is provided this isn't invoked.\n",
        "                if resume_step:\n",
        "                    if resume_step == j:\n",
        "                        resume_step = 0\n",
        "                    else:\n",
        "                        continue\n",
        "                global_step = (j + 1) + i * len(iterator)\n",
        "\n",
        "                model.train()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                outputs = model(x)\n",
        "                loss = loss_fn(outputs, y)\n",
        "\n",
        "                if not math.isfinite(loss.item()) or torch.isnan(loss):\n",
        "                    print(f\"Loss is {loss.item()}... stopping training!\")\n",
        "                    return # Just return to stop training ¯\\_(ツ)_/¯\n",
        "                \n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                lr_scheduler.step()\n",
        "                metric.update(loss.cpu().item())\n",
        "\n",
        "                if global_step % log_every == 0:\n",
        "                    mean_loss = metric.compute()\n",
        "                    metric = MeanMetric()\n",
        "\n",
        "                    iterator.set_postfix(mean_loss=mean_loss.item())\n",
        "                    writer.scalar(\"Loss/train\", mean_loss, global_step)\n",
        "                \n",
        "                if global_step % eval_every == 0:\n",
        "                    outputs = inference(\n",
        "                        model, test_samples, device=device)\n",
        "\n",
        "                    writer.images(\n",
        "                        \"Images/test_outputs\", \n",
        "                        masks2imgs(outputs),\n",
        "                        global_step)\n",
        "\n",
        "                    eval_mean_loss = evaluate(\n",
        "                        model, \n",
        "                        eval_dataloader, \n",
        "                        loss_fn, \n",
        "                        device=device,\n",
        "                        tqdm_config=tqdm_config)\n",
        "                    \n",
        "                    iterator.set_postfix(\n",
        "                        eval_mean_loss=eval_mean_loss.item())\n",
        "                    writer.scalar(\n",
        "                        \"Loss/eval_mean\",\n",
        "                        eval_mean_loss,\n",
        "                        global_step)\n",
        "                    \n",
        "                if global_step % save_every == 0:\n",
        "                    torch.save({\n",
        "                        \"model\": model.state_dict(),\n",
        "                        \"optimizer\": optimizer.state_dict(),\n",
        "                        \"lr_scheduler\": lr_scheduler.state_dict(),\n",
        "                        \"loss\": loss,\n",
        "                        \"epoch\": i,\n",
        "                        \"step\": j,\n",
        "                        \"test_samples\": test_samples,\n",
        "                        \"test_targets\": test_targets\n",
        "                    }, f\"{save_dir}/ckpt_{global_step}\")"
      ],
      "metadata": {
        "id": "5nHLKxqr6Dte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train!"
      ],
      "metadata": {
        "id": "SKLw8nHHVXxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir runs\n",
        "\n",
        "# TODO: save inference samples during training steps \n",
        "\n",
        "train(\n",
        "    model=UNet,\n",
        "    loss_fn=bce_and_softdiceloss,\n",
        "    optimizer=optim.Adam,\n",
        "    lr_scheduler=lr_scheduler.StepLR,\n",
        "    train_dataloader=train_dataloader,\n",
        "    eval_dataloader=test_dataloader,\n",
        "    num_epochs=40,\n",
        "    model_config={\n",
        "        \"num_classes\": 6,\n",
        "        \"in_channels\": 3\n",
        "    },\n",
        "    optimizer_config={\n",
        "        \"lr\": 1e-4\n",
        "    },\n",
        "    lr_scheduler_config={\n",
        "        \"step_size\": 20 * len(train_dataloader),\n",
        "        \"gamma\": 0.1\n",
        "    },\n",
        "    eval_every=50,\n",
        "    save_every=100,\n",
        "    methods=(\"tensorboard\",)\n",
        ")"
      ],
      "metadata": {
        "id": "HkPYKjRvWVe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 👏🏁 📣🎶✨\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://assets.mixkit.co/sfx/download/mixkit-achievement-bell-600.wav\").play()')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "thWjgQWKbVxZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}